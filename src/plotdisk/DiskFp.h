#pragma once
#include "util/Util.h"
#include "plotting/Tables.h"
#include "plotdisk/DiskPlotConfig.h"
#include "plotdisk/DiskBufferQueue.h"
#include "plotdisk/DiskPlotContext.h"
#include "util/BitView.h"

template<TableId table>
struct FpEntry {};

// Unpacked, 64-bit-aligned 
template<> struct FpEntry<TableId::Table1> { uint64 ykey; };              // x, y
template<> struct FpEntry<TableId::Table2> { uint64 ykey; uint64 meta; }; // meta, key, y
template<> struct FpEntry<TableId::Table3> { uint64 ykey; Meta4  meta; };
template<> struct FpEntry<TableId::Table4> { uint64 ykey; Meta4  meta; };
template<> struct FpEntry<TableId::Table5> { uint64 ykey; Meta3  meta; }; // It should be 20, but we use an extra 4 to round up to 64 bits.
template<> struct FpEntry<TableId::Table6> { uint64 ykey; uint64 meta; };
template<> struct FpEntry<TableId::Table7> { uint64 ykey; };

typedef FpEntry<TableId::Table1> T1Entry;
typedef FpEntry<TableId::Table2> T2Entry;
typedef FpEntry<TableId::Table3> T3Entry;
typedef FpEntry<TableId::Table4> T4Entry;
typedef FpEntry<TableId::Table5> T5Entry;
typedef FpEntry<TableId::Table6> T6Entry;
typedef FpEntry<TableId::Table7> T7Entry;

static_assert( sizeof( T1Entry ) == 8  );
static_assert( sizeof( T2Entry ) == 16 );
static_assert( sizeof( T3Entry ) == 24 );
static_assert( sizeof( T4Entry ) == 24 );
static_assert( sizeof( T5Entry ) == 24 );
static_assert( sizeof( T6Entry ) == 16 );
static_assert( sizeof( T7Entry ) == 8  );

template<TableId table, uint32 _numBuckets>
struct DiskPlotInfo
{
    static constexpr uint32 _k = _K;

    using Entry    = FpEntry<table>;
    using TMeta    = typename TableMetaType<table>::MetaOut;

    using InputInfo = DiskPlotInfo<table-1, _numBuckets>;
    
    static constexpr int64  MaxBucketEntries       = (int64)std::ceil( ( static_cast<int64>( (1ull << _k) / _numBuckets ) * BB_DP_XTRA_ENTRIES_PER_BUCKET ) );

    // Size of data outputed/generated by this table
    static constexpr uint32 MetaMultiplier         = static_cast<uint32>( TableMetaOut<table>::Multiplier );

    static constexpr uint32 YBitSize               = _k - bblog2( _numBuckets ) + kExtraBits;
    static constexpr uint32 MapBitSize             = table == TableId::Table1 ? 0 : _k + 1;

    static constexpr uint32 EntrySizePackedBits    = YBitSize + MapBitSize + ( MetaMultiplier * _k );
    static constexpr uint32 EntrySizeExpandedBits  = CDiv( EntrySizePackedBits, 64 ) * 64;

};

template<uint32 _numBuckets>
class IOBitBuffer
{
    uint64*          _buffers;
    size_t           _size;                   // Size per buffer 
    uint32           _count;                  // How many buffers we have. Must have least 2 buffers
    uint32           _curBuffer         = 0;
    uint64           _remainderField    = 0;
    uint32           _remainderBitCount = 0;
    DiskBufferQueue* _queue;
};

template<TableId table, uint32 _numBuckets>
class DiskFp
{
public:
    using InInfo = DiskPlotInfo<table-1, _numBuckets>;
    using Info   = DiskPlotInfo<table, _numBuckets>;

    static constexpr uint32 _k = Info::_k;

    using Entry    = FpEntry<table>;
    using TMeta    = typename TableMetaType<table>::MetaOut;
    using TAddress = uint64;


public:

    //-----------------------------------------------------------
    inline DiskFp( DiskPlotContext& context )
        : _context( context )
        , _ioQueue( *context.ioQueue )
        , _inFxId ( FileId::FX0 )
        , _outFxId( FileId::FX1 )
        // , _bucket ( 0 )
    {

    }

    //-----------------------------------------------------------
    inline void Run()
    {

    }

private:
    //-----------------------------------------------------------
    inline void FpTable()
    {
        // Load initial bucket
        LoadBucket( 0 );

        for( uint32 bucket = 0; bucket < _numBuckets; bucket++ )
        {
            // Load next bucket in the background
            if( bucket + 1 < _numBuckets )
                LoadBucket( bucket + 1 );

            _readFence.Wait( bucket + 1, _readWaitTime );
            FpBucket( bucket );
        }
    }

    //-----------------------------------------------------------
    inline void FpBucket( const uint32 bucket )
    {
        const int64 inEntryCount = (int64)_context.bucketCounts[(int)table-1][bucket];
        const bool  isLastBucket = bucket + 1 == _numBuckets;

        const byte* packedEntries = GetReadBufferForBucket( bucket );

        // Expand entries to be 64-bit aligned, sort them, then unpack them to individual components
        ExpandEntries( packedEntries, _entries, inEntryCount );
        SortEntries( _entries, inEntryCount );
        UnpackEntries( _entries, inEntryCount, _y[0], _map[0], _meta[0] );
        
        // Expand cross bucket entries
        const int64 crossBucketEntryCount = isLastBucket ? 0 : BB_DP_CROSS_BUCKET_MAX_ENTRIES;
        if( crossBucketEntryCount )
        {
            const size_t packedEntrySize = InInfo::EntrySizePackedBits;
            const size_t bitCapacity     = RoundUpToNextBoundary( crossBucketEntryCount * packedEntrySize, 64 );

            ExpandEntries( packedEntries 0, bitCapacity, _entries + inEntryCount, crossBucketEntryCount );
            SortEntries( _entries+inEntryCount, crossBucketEntryCount );
            UnpackEntries( _entries+inEntryCount, crossBucketEntryCount, 
                           _y[0]+inEntryCount, _map[0]+inEntryCount, _meta[0]+inEntryCount );
        }

        // Write reverse-map
        WriteReverseMap( _map[0], inEntryCount );

        // Match groups
        const int64 outEntryCount = MatchEntries( _y[0], _pairs[0], inEntryCount + crossBucketEntryCount );

        // Write pairs
        EncodeAndWritePairs( _pairs[0], outEntryCount );

        // FxGen
        FxGen( outEntryCount, _pairs[0], _y[0], _y[1], _meta[0], _meta[1] );

        // Write new entries to disk
        WriteEntriesToDisk( outEntryCount, _y[1], _meta[1] );

        // Save bucket length before y-sort since the pairs remain unsorted
    }

    //-----------------------------------------------------------
    inline void SortEntries( Entry* entries, Entry* tmpEntries, const int64 entryCount )
    {
        AnonPrefixSumJob<uint32>::Run( _pool, [=]( AnonPrefixSumJob<uint32>* self ) {
            
            int64 count, offset, end;
            GetThreadOffsets( self, entryCount, count, offset, end );

            const uint32 remainderBits = _k - InInfo::YBitSize;
            EntrySort( self, count, offset, entries, tmpEntries, remainderBits );
        });
    }

    //-----------------------------------------------------------
    template<typename T, typename TJob, typename BucketT>
    inline static void EntrySort( PrefixSumJob<TJob, BucketT>* self, const int64 entryCount, const int64 offset, 
                                  T* entries, T* tmpEntries, const uint32 remainderBits )
    {
        ASSERT( self );
        ASSERT( entries );
        ASSERT( tmpEntries );
        ASSERT( entryCount > 0);

        constexpr uint Radix = 256;

        constexpr int32  iterations = 4;
        constexpr uint32 shiftBase  = 8;

        BucketT counts     [Radix];
        BucketT pfxSum     [Radix];
        BucketT totalCounts[Radix];

        uint32 shift = 0;
        T* input  = entries;
        T* output = tmpEntries;

        const uint32 lastByteMask = 0xFF >> remainderBits;
        uint32 masks[iterations]  = { 0xFF, 0xFF, 0xFF, lastByteMask };

        for( int32 iter = 0; iter < iterations ; iter++, shift += shiftBase )
        {
            const uint32 mask = masks[iter];

            // Zero-out the counts
            memset( counts, 0, sizeof( BucketT ) * Radix );

            T*       src   = input + offset;
            const T* start = src;
            const T* end   = start + entryCount;

            do {
                counts[(src->ykey >> shift) & mask]++;
            } while( ++src < end );

            self->CalculatePrefixSum( Radix, counts, pfxSum, totalCounts );

            while( --src >= start )
            {
                const T       value  = *src;
                const uint64  bucket = (value.ykey >> shift) & mask;

                const BucketT dstIdx = --pfxSum[bucket];
                
                output[dstIdx] = value;
            }

            std::swap( input, output );
            self->SyncThreads();
        }
    }

    //-----------------------------------------------------------
    // Convert entries from packed bits into 64-bit aligned entries
    //-----------------------------------------------------------
    inline void ExpandEntries( const void* packedEntries, const uint64 inputBitOffset, Entry* expendedEntries, const int64 entryCount )
    {
        AnonMTJob::Run( _pool, [=]( AnonMTJob* self ) {
            
            constexpr uint32 packedEntrySize = InInfo::EntrySizePackedBits;

            int64 count, offset, end;
            GetThreadOffsets( self, entryCount, count, offset, end );
            
            const uint64 inputBitOffset = packedEntrySize * (uint64)offset;
            const size_t bitCapacity    = CDiv( packedEntrySize * (uint64)entryCount, 64 ) * 64;

            ExpandEntries( packedEntries, inputBitOffset, bitCapacity, expendedEntries + offset, count );
        });
    }

    //-----------------------------------------------------------
    inline static void ExpandEntries( const void* packedEntries, const uint64 inputBitOffset, const size_t bitCapacity,
                                      Entry* expendedEntries, const int64 entryCount )
    {
        constexpr uint32 yBits           = InInfo::YBitSize;
        constexpr uint32 mapBits         = InInfo::MapBits;
        constexpr uint32 metaMultipler   = InInfo::MetaMultiplier;
        constexpr uint32 packedEntrySize = InInfo::EntrySizePackedBits;
        
        BitReader reader( (uint64*)packedEntries, CDiv( (uint64)entryCount * packedEntrySize, 64 ) * 64, inputBitOffset );

              Entry* out = expendedEntries;
        const Entry* end = out + entryCount;
        
        for( ; out < end; out++ )
        {
            const uint64 y   = reader.ReadBits64( yBits    );
            const uint64 map = reader.ReadBits64( mapBits  );

            out->ykey = y | ( map << yBits );

            if constexpr ( metaMultipler == 2 )
            {
                out->meta = reader.ReadBits64( 64 );
            }
            else if constexpr ( metaMultipler == 3 )
            {
                // #TODO: Try aligning entries to 32-bits instead.
                out->meta.m0 = reader.ReadBits64( 64 );
                out->meta.m1 = reader.ReadBits64( 32 );
            }
            else if constexpr ( metaMultipler == 4 )
            {
                out->meta.m0 = reader.ReadBits64( 64 );
                out->meta.m1 = reader.ReadBits64( 64 );
            }
        }
    }
    
    //-----------------------------------------------------------
    inline void LoadBucket( const uint32 bucket )
    {
        const uint64 inBucketLength  = _context.bucketCounts[(int)table-1][bucket];
        const size_t bucketSizeBytes = CDiv( InInfo::EntrySizePackedBits * (uint64)inBucketLength, 64 ) * 64 / 8;

        byte* readBuffer = GetReadBufferForBucket( bucket );
        _ioQueue.SeekFile( _inFxId, bucket, 0, SeekOrigin::Begin );
        _ioQueue.ReadFile( _inFxId, bucket, readBuffer, bucketSizeBytes );
        
        // We need to read a little bit from the next bucket as well, so we can do proper group matching across buckets
        if( bucket+1 < _numBuckets )
        {
            const size_t nextBucketLoadSize = CDiv( InInfo::EntrySizePackedBits * (uint64)BB_DP_CROSS_BUCKET_MAX_ENTRIES, 64 ) * 64 / 8;
            
            _ioQueue.SeekFile( _inFxId, bucket+1, 0, SeekOrigin::Begin );
            _ioQueue.ReadFile( _inFxId, bucket+1, readBuffer + bucketSizeBytes, nextBucketLoadSize );
        }
        _ioQueue.SignalFence( _readFence, bucket+1 );
        _ioQueue.CommitCommands();
    }

    //-----------------------------------------------------------
    inline byte* GetReadBufferForBucket( const uint32 bucket )
    {
        return _readBuffers + bucket % 2;
    }

    //-----------------------------------------------------------
    template<typename TJob, typename T>
    inline static void GetThreadOffsets( MTJob<TJob>* job, const T totalCount, T& count, T& offset, T& end )
    {
        GetThreadOffsets( job->JobId(), job->JobCount(), totalCount, count, offset, end );
    }

    //-----------------------------------------------------------
    template<typename T>
    inline static void GetThreadOffsets( const uint32 id, const uint32 threadCount, const T totalCount, T& count, T& offset, T& end )
    {
        const T countPerThread = totalCount / (T)threadCount
        const T remainder      = totalCount - countPerThread * (T)threadCount;

        count  = countPerThread;
        offset = (T)id * countPerThread;

        if( id == threadCount-1 )
            count += remainder;
        
        end = offset + count;
    }

private:
    DiskPlotContext& _context    ;
    ThreadPool&      _pool       ;
    DiskBufferQueue& _ioQueue    ;
    FileId           _inFxId     ;
    FileId           _outFxId    ;
    byte**           _readBuffers;
    Fence            _readFence ;
    Fence            _writeFence;

    Duration         _readWaitTime = Duration::zero();

    // Working buffers, all of them have enough to hold  entries for a single bucket + cross bucket entries
    Entry*  _entries;   // Unpacked entries
    uint64* _y   [2];
    uint64* _map [1];
    TMeta*  _meta[2];
    Pair*   _pair[2];

    // For simplicity when doing mult-threaded bucket processing
    // int64            _bucketEntryCount;
    // int64            _lengths[BB_DP_MAX_JOBS];
    // int64            _offsets[BB_DP_MAX_JOBS];
    // int64            _ends   [BB_DP_MAX_JOBS];
    // uint32           _bucket    ;
};